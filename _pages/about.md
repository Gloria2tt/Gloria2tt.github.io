---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I obtained my Master's degree from [Tsinghua University](https://www.tsinghua.edu.cn/), Beijing, China. I am currently working at **WeChat AI, Tencent**. Prior to this, I worked at **Baidu** on LLM post-training for [ERNIE / Wenxin Yiyan (ÊñáÂøÉ‰∏ÄË®Ä)](https://yiyan.baidu.com/). My research interests lie in **Multimodal Learning** and **Large Language Models (LLMs)**






# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IJCV 2026</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[HarmoniDPO: Video-guided Audio Generation via Preference-Optimized Diffusion](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=1RlWdF0AAAAJ&citation_for_view=1RlWdF0AAAAJ:Y0pCki6q_DkC)

**Wenshuo Peng**, Kaipeng Zhang

**International Journal of Computer Vision (IJCV)**, 2026

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2024</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Data Adaptive Traceback for Vision-Language Foundation Models in Image Classification](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=1RlWdF0AAAAJ&citation_for_view=1RlWdF0AAAAJ:u-x6o8ySG0sC)

**Wenshuo Peng**, Kaipeng Zhang, Yang Yang, Hao Zhang, Yu Qiao

**Proceedings of the AAAI Conference on Artificial Intelligence**, 38(5), 4506-4514, 2024

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NAACL 2024</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[T3M: Text Guided 3D Human Motion Synthesis from Speech](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=1RlWdF0AAAAJ&citation_for_view=1RlWdF0AAAAJ:d1gkVwhDpl0C)

**Wenshuo Peng**, Kaipeng Zhang, Shu-Quan Zhang

**Findings of the Association for Computational Linguistics: NAACL 2024**, 1168-1177

</div>
</div>

- [SVBench: Evaluation of Video Generation Models on Social Reasoning](https://arxiv.org/abs/2512.21507), **Wenshuo Peng**, Guangyao Wang, Tianshu Yang, Chunhao Li, Xiangtai Xu, Haohan He, Kaipeng Zhang, *arXiv 2025*

- [Yume: An Interactive World Generation Model](https://arxiv.org/abs/2507.17744), Xiangyu Mao, Shaofeng Lin, Zhenyu Li, Chunhao Li, **Wenshuo Peng**, Tianyu He, Jiangmiao Pang, Mingyu Chi, Yu Qiao, Kaipeng Zhang, *arXiv 2025*

- [ERNIE 4.5 Technical Report](https://yiyan.baidu.com/blog/publication/ERNIE_Technical_Report.pdf), Baidu ERNIE Team, *2025*

- [Multi-relational Pedestrian Trajectory Prediction in Complex Scenes](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=1RlWdF0AAAAJ&citation_for_view=1RlWdF0AAAAJ:9yKSN-GCB0IC), **Wenshuo Peng**, Zhengxia Cui, Yuxin Duan, Xiao Tao, **IEEE VTC 2022**

# üìñ Educations
- *2021.09 - 2024.06*, M.S., Tsinghua University, Beijing, China. 

# üíª Work Experience
- *2026 - Present*, WeChat AI, Tencent, Beijing, China.
- *2024 - 2025*, Baidu, Beijing, China. LLM post-training for ERNIE / Wenxin Yiyan (ÊñáÂøÉ‰∏ÄË®Ä).
